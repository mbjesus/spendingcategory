{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Brazil\n",
    "## Goi√°s State Court of Accounts\n",
    "### Department of Strategic Information\n",
    "\n",
    "This document describes the data mining process for predicting whether a particular public spend is for advertising based on text mining.\n",
    "\n",
    "Author: Mauricio Barros de Jesus on 04/19/2019\n",
    "Paper: Using text mining to categorize the purpose of public spending for the benefit of transparency and accountability - ICMLA 2019.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import  NaiveBayes, NaiveBayesModel,MultilayerPerceptronClassifier,MultilayerPerceptronClassifier,LogisticRegression,LinearSVC,RandomForestClassifier\n",
    "from pyspark.ml.feature import HashingTF, Tokenizer, IDF, StopWordsRemover, CountVectorizer,StringIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator,BinaryClassificationEvaluator\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import col, lower, regexp_replace\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics,MulticlassMetrics\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.stem import SnowballStemmer\n",
    "pt_stemmer = SnowballStemmer('portuguese')\n",
    "\n",
    "#Show graphics on notebook\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spark Session\n",
    "spSession = SparkSession.builder.master(\"local\").appName(\"TCEGO\").config(\"spark.some.config.option\", \"session\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data set from Hadoop HDFS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Dataset \n",
    "dfEmpenhos = spSession.read.csv('hdfs://your_server:your_port/your_path/ds_icmla_spendingcategory.csv',header=True, sep=\";\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfEmpenhos.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfEmpenhos = dfEmpenhos.repartition(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfEmpenhos.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['key_nr_empenho', 'desc_empenho', 'e_natureza_publicidade', 'key_nat_desp']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfEmpenhos.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter Columns\n",
    "dfEmpenhos = dfEmpenhos[[\"key_nr_empenho\",\"desc_empenho\",\"e_natureza_publicidade\",\"key_nat_desp\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "143487"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show instaces number\n",
    "dfEmpenhos.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+\n",
      "|e_natureza_publicidade|\n",
      "+----------------------+\n",
      "|                     3|\n",
      "|                     0|\n",
      "|                     1|\n",
      "|                     2|\n",
      "+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show class\n",
    "dfEmpenhos.select(\"e_natureza_publicidade\").distinct().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+------+\n",
      "|e_natureza_publicidade| count|\n",
      "+----------------------+------+\n",
      "|                     3|  2454|\n",
      "|                     0|122858|\n",
      "|                     1|  1168|\n",
      "|                     2| 17007|\n",
      "+----------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count instances by classes\n",
    "dfEmpenhos.groupBy(\"e_natureza_publicidade\").count().show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mudarAtributoClasse(lrow):\n",
    "    \n",
    "    e_natureza_publicidade = float(lrow[\"e_natureza_publicidade\"])\n",
    "    \n",
    "    #change class number 3 to zero and current zero to 2 (unknown class)\n",
    "    if e_natureza_publicidade == 0.0:\n",
    "        natureza = 2.0\n",
    "    elif (e_natureza_publicidade == 3.0):\n",
    "        natureza = 0.0\n",
    "    elif (e_natureza_publicidade == 1.0):\n",
    "        natureza = 1.0\n",
    "    else:\n",
    "        natureza = 2.0\n",
    "        \n",
    "    linhas = Row(key_nr_empenho = lrow[\"key_nr_empenho\"], desc_empenho = lrow[\"desc_empenho\"], e_natureza_publicidade = float(natureza))\n",
    "    return linhas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/pandas/compat/__init__.py:85: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "##Filtering Known Classes\n",
    "empenhosDFDML_TMP = dfEmpenhos.rdd.map(mudarAtributoClasse).toDF()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+------+\n",
      "|e_natureza_publicidade| count|\n",
      "+----------------------+------+\n",
      "|                   0.0|  2454|\n",
      "|                   1.0|  1168|\n",
      "|                   2.0|139865|\n",
      "+----------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count instances by classes\n",
    "empenhosDFDML_TMP.groupBy(\"e_natureza_publicidade\").count().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only labeled instances (0: No advertising; 1: Advertising)\n",
    "empenhosDFML = empenhosDFDML_TMP.rdd.filter(lambda x: x[\"e_natureza_publicidade\"] == 0 or x[\"e_natureza_publicidade\"] == 1).toDF()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+-----+\n",
      "|e_natureza_publicidade|count|\n",
      "+----------------------+-----+\n",
      "|                   0.0| 2454|\n",
      "|                   1.0| 1168|\n",
      "+----------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "empenhosDFML.groupBy(\"e_natureza_publicidade\").count().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------------+----------------+\n",
      "|        desc_empenho|e_natureza_publicidade|  key_nr_empenho|\n",
      "+--------------------+----------------------+----------------+\n",
      "|empenho tratase d...|                   1.0|2017660501000076|\n",
      "|item qtd un      ...|                   0.0|2017070100600821|\n",
      "+--------------------+----------------------+----------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "empenhosDFML.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------------------+--------------------+\n",
      "|  key_nr_empenho|e_natureza_publicidade|        desc_empenho|\n",
      "+----------------+----------------------+--------------------+\n",
      "|2018045201300163|                   1.0|empenho  referent...|\n",
      "|2017670101600122|                   1.0|valor destinado a...|\n",
      "|2018010102800439|                   0.0|referente a auxil...|\n",
      "|2018020100500184|                   0.0|quantia que se em...|\n",
      "|2018045201300101|                   1.0|modalidade de lic...|\n",
      "|2017670101600114|                   1.0|valor destinado a...|\n",
      "|2017385400600064|                   0.0|empenhase para co...|\n",
      "|2017290201100070|                   0.0|empenho referente...|\n",
      "|2015290200500191|                   0.0|destinase ao paga...|\n",
      "|2015290200500111|                   0.0|destinase ao paga...|\n",
      "+----------------+----------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Remove punctuation\n",
    "empenhosFinal = empenhosDFML.select('key_nr_empenho','e_natureza_publicidade', (lower(regexp_replace('desc_empenho', \"[?|¬∫|¬∞|`|¬ø|$|&|*|%|@|(|)|~|,|\\.|:|\\-|\\'|/]\", \" \")).alias('desc_empenho')))\n",
    "empenhosFinal.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/pi/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/pi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['de',\n",
       " 'a',\n",
       " 'o',\n",
       " 'que',\n",
       " 'e',\n",
       " '√©',\n",
       " 'do',\n",
       " 'da',\n",
       " 'em',\n",
       " 'um',\n",
       " 'para',\n",
       " 'com',\n",
       " 'n√£o',\n",
       " 'uma',\n",
       " 'os',\n",
       " 'no',\n",
       " 'se',\n",
       " 'na',\n",
       " 'por',\n",
       " 'mais',\n",
       " 'as',\n",
       " 'dos',\n",
       " 'como',\n",
       " 'mas',\n",
       " 'ao',\n",
       " 'ele',\n",
       " 'das',\n",
       " '√†',\n",
       " 'seu',\n",
       " 'sua',\n",
       " 'ou',\n",
       " 'quando',\n",
       " 'muito',\n",
       " 'nos',\n",
       " 'j√°',\n",
       " 'eu',\n",
       " 'tamb√©m',\n",
       " 's√≥',\n",
       " 'pelo',\n",
       " 'pela',\n",
       " 'at√©',\n",
       " 'isso',\n",
       " 'ela',\n",
       " 'entre',\n",
       " 'depois',\n",
       " 'sem',\n",
       " 'mesmo',\n",
       " 'aos',\n",
       " 'seus',\n",
       " 'quem',\n",
       " 'nas',\n",
       " 'me',\n",
       " 'esse',\n",
       " 'eles',\n",
       " 'voc√™',\n",
       " 'essa',\n",
       " 'num',\n",
       " 'nem',\n",
       " 'suas',\n",
       " 'meu',\n",
       " '√†s',\n",
       " 'minha',\n",
       " 'numa',\n",
       " 'pelos',\n",
       " 'elas',\n",
       " 'qual',\n",
       " 'n√≥s',\n",
       " 'lhe',\n",
       " 'deles',\n",
       " 'essas',\n",
       " 'esses',\n",
       " 'pelas',\n",
       " 'este',\n",
       " 'dele',\n",
       " 'tu',\n",
       " 'te',\n",
       " 'voc√™s',\n",
       " 'vos',\n",
       " 'lhes',\n",
       " 'meus',\n",
       " 'minhas',\n",
       " 'teu',\n",
       " 'tua',\n",
       " 'teus',\n",
       " 'tuas',\n",
       " 'nosso',\n",
       " 'nossa',\n",
       " 'nossos',\n",
       " 'nossas',\n",
       " 'dela',\n",
       " 'delas',\n",
       " 'esta',\n",
       " 'estes',\n",
       " 'estas',\n",
       " 'aquele',\n",
       " 'aquela',\n",
       " 'aqueles',\n",
       " 'aquelas',\n",
       " 'isto',\n",
       " 'aquilo',\n",
       " 'estou',\n",
       " 'est√°',\n",
       " 'estamos',\n",
       " 'est√£o',\n",
       " 'estive',\n",
       " 'esteve',\n",
       " 'estivemos',\n",
       " 'estiveram',\n",
       " 'estava',\n",
       " 'est√°vamos',\n",
       " 'estavam',\n",
       " 'estivera',\n",
       " 'estiv√©ramos',\n",
       " 'esteja',\n",
       " 'estejamos',\n",
       " 'estejam',\n",
       " 'estivesse',\n",
       " 'estiv√©ssemos',\n",
       " 'estivessem',\n",
       " 'estiver',\n",
       " 'estivermos',\n",
       " 'estiverem',\n",
       " 'hei',\n",
       " 'h√°',\n",
       " 'havemos',\n",
       " 'h√£o',\n",
       " 'houve',\n",
       " 'houvemos',\n",
       " 'houveram',\n",
       " 'houvera',\n",
       " 'houv√©ramos',\n",
       " 'haja',\n",
       " 'hajamos',\n",
       " 'hajam',\n",
       " 'houvesse',\n",
       " 'houv√©ssemos',\n",
       " 'houvessem',\n",
       " 'houver',\n",
       " 'houvermos',\n",
       " 'houverem',\n",
       " 'houverei',\n",
       " 'houver√°',\n",
       " 'houveremos',\n",
       " 'houver√£o',\n",
       " 'houveria',\n",
       " 'houver√≠amos',\n",
       " 'houveriam',\n",
       " 'sou',\n",
       " 'somos',\n",
       " 's√£o',\n",
       " 'era',\n",
       " '√©ramos',\n",
       " 'eram',\n",
       " 'fui',\n",
       " 'foi',\n",
       " 'fomos',\n",
       " 'foram',\n",
       " 'fora',\n",
       " 'f√¥ramos',\n",
       " 'seja',\n",
       " 'sejamos',\n",
       " 'sejam',\n",
       " 'fosse',\n",
       " 'f√¥ssemos',\n",
       " 'fossem',\n",
       " 'for',\n",
       " 'formos',\n",
       " 'forem',\n",
       " 'serei',\n",
       " 'ser√°',\n",
       " 'seremos',\n",
       " 'ser√£o',\n",
       " 'seria',\n",
       " 'ser√≠amos',\n",
       " 'seriam',\n",
       " 'tenho',\n",
       " 'tem',\n",
       " 'temos',\n",
       " 't√©m',\n",
       " 'tinha',\n",
       " 't√≠nhamos',\n",
       " 'tinham',\n",
       " 'tive',\n",
       " 'teve',\n",
       " 'tivemos',\n",
       " 'tiveram',\n",
       " 'tivera',\n",
       " 'tiv√©ramos',\n",
       " 'tenha',\n",
       " 'tenhamos',\n",
       " 'tenham',\n",
       " 'tivesse',\n",
       " 'tiv√©ssemos',\n",
       " 'tivessem',\n",
       " 'tiver',\n",
       " 'tivermos',\n",
       " 'tiverem',\n",
       " 'terei',\n",
       " 'ter√°',\n",
       " 'teremos',\n",
       " 'ter√£o',\n",
       " 'teria',\n",
       " 'ter√≠amos',\n",
       " 'teriam',\n",
       " 'vlr',\n",
       " 'un',\n",
       " 'tot',\n",
       " 'qtd',\n",
       " 'qt',\n",
       " 'valor',\n",
       " 'no',\n",
       " 'pdf',\n",
       " '2010',\n",
       " '2011',\n",
       " '2012',\n",
       " '2013',\n",
       " '2015',\n",
       " '2016',\n",
       " '2017',\n",
       " 'mes',\n",
       " 'm√™s',\n",
       " 'ata',\n",
       " '0012013',\n",
       " 'ppt',\n",
       " 'total',\n",
       " 'goi√°s',\n",
       " '02',\n",
       " 'fls',\n",
       " 'fl',\n",
       " '03',\n",
       " '01',\n",
       " 'n¬∫',\n",
       " 'dps',\n",
       " 'ddo',\n",
       " 'rds',\n",
       " 'jjbn',\n",
       " 'rdf',\n",
       " 'ser',\n",
       " 'meses',\n",
       " 'tipo',\n",
       " 'obs',\n",
       " 'doze',\n",
       " '12',\n",
       " 'al√©m',\n",
       " 'bem',\n",
       " 'rjus',\n",
       " '25042017',\n",
       " 'fazer',\n",
       " 'face']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Stop Words List\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "stopword_list_nltk = nltk.corpus.stopwords.words('portuguese')\n",
    "\n",
    "## Adding stopwords informed by the experts.\n",
    "stopword_list_nltk.append(\"VLR\")\n",
    "stopword_list_nltk.append(\"UN\")\n",
    "stopword_list_nltk.append(\"TOT\")\n",
    "stopword_list_nltk.append(\"QTD\")\n",
    "stopword_list_nltk.append(\"QT\")\n",
    "stopword_list_nltk.append(\"VALOR\")\n",
    "stopword_list_nltk.append(\"NO\")\n",
    "stopword_list_nltk.append(\"PDF\")\n",
    "stopword_list_nltk.append(\"2010\")\n",
    "stopword_list_nltk.append(\"2011\")\n",
    "stopword_list_nltk.append(\"2012\")\n",
    "stopword_list_nltk.append(\"2013\")\n",
    "stopword_list_nltk.append(\"2015\")\n",
    "stopword_list_nltk.append(\"2016\")\n",
    "stopword_list_nltk.append(\"2017\")\n",
    "stopword_list_nltk.append(\"MES\")\n",
    "stopword_list_nltk.append(\"M√äS\")\n",
    "stopword_list_nltk.append(\"ATA\")\n",
    "stopword_list_nltk.append(\"0012013\")\n",
    "stopword_list_nltk.append(\"PPT\")\n",
    "stopword_list_nltk.append(\"TOTAL\")\n",
    "stopword_list_nltk.append(\"GOI√ÅS\")\n",
    "stopword_list_nltk.append(\"02\")\n",
    "stopword_list_nltk.append(\"FLS\")\n",
    "stopword_list_nltk.append(\"FL\")\n",
    "stopword_list_nltk.append(\"03\")\n",
    "stopword_list_nltk.append(\"01\")\n",
    "stopword_list_nltk.append(\"N¬∫\")\n",
    "stopword_list_nltk.append(\"DPS\")\n",
    "stopword_list_nltk.append(\"DDO\")\n",
    "stopword_list_nltk.append(\"RDS\")\n",
    "stopword_list_nltk.append(\"jjbn\")\n",
    "stopword_list_nltk.append(\"rdf\")\n",
    "stopword_list_nltk.append(\"ser\")\n",
    "stopword_list_nltk.append(\"meses\")\n",
    "stopword_list_nltk.append(\"tipo\")\n",
    "stopword_list_nltk.append(\"obs\")\n",
    "stopword_list_nltk.append(\"doze\")\n",
    "stopword_list_nltk.append(\"12\")\n",
    "stopword_list_nltk.append(\"al√©m\")\n",
    "stopword_list_nltk.append(\"bem\")\n",
    "stopword_list_nltk.append(\"rjus\")\n",
    "stopword_list_nltk.append(\"25042017\")\n",
    "stopword_list_nltk.append(\"fazer\")\n",
    "stopword_list_nltk.append(\"face\")\n",
    "\n",
    "stopword_list = []\n",
    "[stopword_list.append(i.lower())  for i in stopword_list_nltk]\n",
    "stopword_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline Steps: Tokenization, Stopwords Removal, and TF-IDF\n",
    "tokenizer = Tokenizer(inputCol = \"desc_empenho\", outputCol = \"words\")\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\",stopWords=stopword_list)\n",
    "hashingTF = HashingTF(inputCol = remover.getOutputCol(), outputCol = \"tempfeatures\")\n",
    "idf = IDF(inputCol = hashingTF.getOutputCol(), outputCol = \"features\", minDocFreq=5)\n",
    "label_stringIdx = StringIndexer(inputCol = \"e_natureza_publicidade\", outputCol = \"label\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline Creation\n",
    "pipeline = Pipeline(stages = [tokenizer,remover,hashingTF,idf,label_stringIdx])\n",
    "\n",
    "pipelineFit = pipeline.fit(empenhosFinal)\n",
    "dataset = pipelineFit.transform(empenhosFinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|  key_nr_empenho|e_natureza_publicidade|        desc_empenho|               words|            filtered|        tempfeatures|            features|label|\n",
      "+----------------+----------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|2017385400600064|                   0.0|empenhase para co...|[empenhase, para,...|[empenhase, cobri...|(262144,[6419,555...|(262144,[6419,555...|  0.0|\n",
      "|2017290201100070|                   0.0|empenho referente...|[empenho, referen...|[empenho, referen...|(262144,[1251,528...|(262144,[1251,528...|  0.0|\n",
      "|2016220100700522|                   0.0|valor que se empe...|[valor, que, se, ...|[empenha, empresa...|(262144,[5590,222...|(262144,[5590,222...|  0.0|\n",
      "|2016220217800009|                   0.0|valor que se empe...|[valor, que, se, ...|[empenha, empresa...|(262144,[3199,458...|(262144,[3199,458...|  0.0|\n",
      "|2016270300100001|                   0.0|empenho referente...|[empenho, referen...|[empenho, referen...|(262144,[14976,29...|(262144,[14976,29...|  0.0|\n",
      "|2016230100400293|                   0.0|  # empenho refer...|[, , #, empenho, ...|[, , #, empenho, ...|(262144,[1725,179...|(262144,[1725,179...|  0.0|\n",
      "|2015045201102429|                   0.0|empenho  referent...|[empenho, , refer...|[empenho, , refer...|(262144,[5284,559...|(262144,[5284,559...|  0.0|\n",
      "|2018285005600006|                   0.0| fes  fonte 223 h...|[, fes, , fonte, ...|[, fes, , fonte, ...|(262144,[1936,484...|(262144,[1936,484...|  0.0|\n",
      "|2017660501000076|                   1.0|empenho tratase d...|[empenho, tratase...|[empenho, tratase...|(262144,[452,1936...|(262144,[452,1936...|  1.0|\n",
      "|2015290200500191|                   0.0|destinase ao paga...|[destinase, ao, p...|[destinase, pagam...|(262144,[6582,879...|(262144,[6582,879...|  0.0|\n",
      "+----------------+----------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Holdout - Training and test data (70% training, 30% test)\n",
    "(dados_treino, dados_teste) = dataset.randomSplit([0.7, 0.3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imbalance classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1035"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados_teste.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(filtered=['empenho', '', 'referente', '', '', 'contrata√ß√£o', '', 'empresa', 'especializada', 'presta√ß√£o', 'deservi√ßos', '', '', 'gerenciamento', 'abastecimento', 've√≠culos', '', 'mediante', 'emiss√£ode', 'cart√µes', 'magn√©ticos', 'controle', 'consumo', '', 'frota', 've√≠culos', 'levese', '', 'pesados', '', '', 'tribunal', '', '', 'justi√ßa', '', '', 'estado', '', '', 'per√≠odo', 'de12', '', 'oriunda', 'edital', 'licita√ß√£o', 'n', '', '0802015', '', '', '', 'modalidadepreg√£o', '', 'eletr√¥nico', '', '', '', 'menor', '', 'pre√ßo', '', 'conforme', 'despacho', 'n', '', '0029342015da', 'diretoria', 'geral', 'doc', '', '100', 'especifica√ß√£o', 'abaixo', '', '', 'item', '', '', '', '', '', 'und', '', '', 'especifica√ß√£o', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 'vl', '', 'unit', '', '', '', '', '', '', 'vl', '', 'mensal03', '', '', '30', '000', '', 'litro', '', 'etanol', 'comum', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '2', '32', '', '', '', '', '', '', '', '69', '600', '00desconto', '2', '19', '', 'conforme', 'proposta', 'doc', '', '82', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '1', '524', '24', 'anual', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 'r', '68', '075', '76valor', 'mensal', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 'r', '', '5', '672', '98valor', 'di√°rio', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 'r', '', '', '', '189', '10', 'po', 'per√≠odo', '28122015', '31122015', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 'r', '', '', '', '567', '30', '', 'dados', 'banc√°rios', 'banco001', '', 'ag', '31682', '', 'c', 'c', '146943', '', 'aten√ß√£o', '1', '', 'emitir', 'nota', 'fiscal', 'nome', 'fundo', 'especial', 'reaparelhamento', 'moderniza√ß√£o', 'poder', 'judici√°rio', '', 'cnpj', 'n', '', '050', '330000117', '', '2', '', 'indicar', 'nota', 'fiscal', 'n', '', 'empenho', 'constante', 'campos', '5', '7', 'dueof', 'n', 'processocampo', '19', 'dueofe', 'dados', 'banc√°rios', 'benefici√°', 'rio', '', 'contendo', 'nome', 'c√≥digo', 'banco', '', 'ag√™ncia', 'conta', 'corrente', '', '3para', 'consultar', 'programa√ß√£o', 'rela√ß√£o', 'pagamentos', 'efetuados', 'acesse', 'endere√ßo', 'eletr√¥nicohttpwww', 'tjgo', 'jus', 'br', 'institucionaldepartamento', 'financeira']),\n",
       " Row(filtered=['reempenho', 'ne', 'n', '', '6601', '019', '00461', 'referente', 'servi√ßos', 'publicidade', 'divulga√ß√£o', 'informativaeducativa', 'obrigatoriedade', 'vacina√ß√£o', 'rebanhos', 'bovinos', 'bubalinos', 'contra', 'febre', 'aftosa', '', '2¬™', 'etapa', '', 'estado', 'despesa', 'autorizada', 'atrav√©s', 'daof', 'n', '', '0041266012016', '26092016', 'base', 'contrato', 'n', '', '0072014', 'n', '', '243', 'autoriza√ß√£o', 'segplan', 'n', '', '13135', '06122016', '1', 'n', '', '1806', 'n', '', '5568', ''])]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.select(\"filtered\").take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validator  (CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generic Function for CrossValidator\n",
    "def executarCV(p_df,p_estimator,p_evaluator,p_grid,nr_folds):\n",
    "    #Define CV\n",
    "    crossval = CrossValidator(estimator=p_estimator,\n",
    "                              evaluator=p_evaluator,\n",
    "                              estimatorParamMaps=p_grid,\n",
    "                              numFolds=nr_folds)\n",
    "    # Executing CV\n",
    "    cvModel = crossval.fit(p_df)\n",
    "    \n",
    "    return cvModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Show data from CV\n",
    "def mostrarCV(cvModel):\n",
    "    # Apresentar resultado de forma amigavel\n",
    "    params = [{p.name: v for p, v in m.items()} for m in cvModel.getEstimatorParamMaps()]\n",
    "    \n",
    "    for ps, metric in zip(params, cvModel.avgMetrics):\n",
    "        print(cvModel.getEvaluator().getMetricName(),ps, metric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Creating Naive Bayes (NB) model\n",
    "nbClassifier = NaiveBayes()\n",
    "nbClassifier.setFeaturesCol(\"features\")\n",
    "nbClassifier.setLabelCol(\"label\")\n",
    "\n",
    "pipelineNB = Pipeline(stages = [nbClassifier])\n",
    "paramGridNB = ParamGridBuilder().addGrid(nbClassifier.smoothing, [0,0.5,1]).build()\n",
    "evaluatorNB = BinaryClassificationEvaluator(rawPredictionCol = \"prediction\", labelCol = \"label\", metricName = \"areaUnderROC\")\n",
    "\n",
    "#Executing NB\n",
    "cvModelNB = executarCV(dados_treino,pipelineNB,evaluatorNB,paramGridNB,5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "areaUnderROC {'smoothing': 0.0} 0.5771869167718134\n",
      "areaUnderROC {'smoothing': 0.5} 0.959479710309446\n",
      "areaUnderROC {'smoothing': 1.0} 0.9555941248084148\n"
     ]
    }
   ],
   "source": [
    "# Show Results\n",
    "mostrarCV(cvModelNB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating LogisticRegression\n",
    "classificadorRL = LogisticRegression(maxIter=10)\n",
    "classificadorRL.setFeaturesCol(\"features\")\n",
    "classificadorRL.setLabelCol(\"label\")\n",
    "\n",
    "pipelineRL = Pipeline(stages = [classificadorRL])\n",
    "paramGridRL = ParamGridBuilder().addGrid(classificadorRL.regParam, [0.1,0.01]).addGrid(classificadorRL.elasticNetParam, [0,0.5]).build()\n",
    "evaluatorRL = BinaryClassificationEvaluator(rawPredictionCol = \"prediction\", labelCol = \"label\", metricName = \"areaUnderROC\")\n",
    "\n",
    "#Executing LogisticRegression in CV \n",
    "cvModelRL = executarCV(dados_treino,pipelineRL,evaluatorRL,paramGridRL,5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "areaUnderROC {'regParam': 0.1, 'elasticNetParam': 0.0} 0.9775708696573728\n",
      "areaUnderROC {'regParam': 0.1, 'elasticNetParam': 0.5} 0.899364150848875\n",
      "areaUnderROC {'regParam': 0.01, 'elasticNetParam': 0.0} 0.9819990047230942\n",
      "areaUnderROC {'regParam': 0.01, 'elasticNetParam': 0.5} 0.974763682418981\n"
     ]
    }
   ],
   "source": [
    "# Show Results\n",
    "mostrarCV(cvModelRL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "areaUnderROC {'regParam': 1.0, 'maxIter': 5} 0.9709553124293372\n",
      "areaUnderROC {'regParam': 1.0, 'maxIter': 10} 0.9775371920651394\n",
      "areaUnderROC {'regParam': 1.0, 'maxIter': 15} 0.9776166170284054\n",
      "areaUnderROC {'regParam': 0.1, 'maxIter': 5} 0.9731876139291639\n",
      "areaUnderROC {'regParam': 0.1, 'maxIter': 10} 0.9810587933953888\n",
      "areaUnderROC {'regParam': 0.1, 'maxIter': 15} 0.9817870889300647\n"
     ]
    }
   ],
   "source": [
    "#Criando modelo com LinearSVC\n",
    "svcClassifier = LinearSVC()\n",
    "svcClassifier.setFeaturesCol(\"features\")\n",
    "svcClassifier.setLabelCol(\"label\")\n",
    "\n",
    "pipelineSVC = Pipeline(stages = [svcClassifier])\n",
    "paramGridSVC = ParamGridBuilder().addGrid(svcClassifier.regParam, [1.0, 0.1]).addGrid(svcClassifier.maxIter, [5,10,15]).build()\n",
    "evaluatorSVC = BinaryClassificationEvaluator(rawPredictionCol = \"prediction\", labelCol = \"label\", metricName = \"areaUnderROC\")\n",
    "\n",
    "#Executing LinearSVC in CV \n",
    "cvModelSVC = executarCV(dados_treino,pipelineSVC,evaluatorSVC,paramGridSVC,5)\n",
    "mostrarCV(cvModelSVC)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostarResultadoTeste(previsoes):\n",
    "    resultados = previsoes.select(['prediction', 'label'])\n",
    "    \n",
    "    ## prepare score-label set\n",
    "    resultados_list = [list(i) for i in resultados.collect()]\n",
    "    predictionAndLabels = sc.parallelize(resultados_list)\n",
    "    \n",
    "    metricsML = MulticlassMetrics(predictionAndLabels)\n",
    "    metricsBI = BinaryClassificationMetrics(predictionAndLabels)\n",
    "    \n",
    "    print(\"Precision: \", metricsML.precision(1.0) , metricsML.precision(0.0))\n",
    "    print(\"Recall: \", metricsML.recall(1.0) , metricsML.recall(0.0))\n",
    "    print(\"fMeasure: \", metricsML.fMeasure(1.0) , metricsML.fMeasure(0.0))\n",
    "    print(\"areaUnderROC: \", metricsBI.areaUnderROC )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.9935275080906149 0.9669421487603306\n",
      "Recall:  0.9274924471299094 0.9971590909090909\n",
      "fMeasure:  0.959375 0.9818181818181819\n",
      "areaUnderROC:  0.9623257690195003\n"
     ]
    }
   ],
   "source": [
    "# Teste NB\n",
    "previsoesNB = cvModelNB.bestModel.transform(dados_teste)\n",
    "mostarResultadoTeste(previsoesNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.996875 0.9832167832167832\n",
      "Recall:  0.9637462235649547 0.9985795454545454\n",
      "fMeasure:  0.9800307219662058 0.9908386187455955\n",
      "areaUnderROC:  0.98116288450975\n"
     ]
    }
   ],
   "source": [
    "# Teste RL\n",
    "previsoesRL = cvModelRL.bestModel.transform(dados_teste)\n",
    "mostarResultadoTeste(previsoesRL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.9968847352024922 0.9845938375350141\n",
      "Recall:  0.9667673716012085 0.9985795454545454\n",
      "fMeasure:  0.9815950920245399 0.9915373765867419\n",
      "areaUnderROC:  0.9826734585278769\n"
     ]
    }
   ],
   "source": [
    "# Tests whit SVC\n",
    "previsoesSVC = cvModelSVC.bestModel.transform(dados_teste)\n",
    "mostarResultadoTeste(previsoesSVC)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Param(parent='CrossValidatorModel_d01b3939eab6', name='estimator', doc='estimator to be cross-validated'),\n",
       " Param(parent='CrossValidatorModel_d01b3939eab6', name='estimatorParamMaps', doc='estimator param maps'),\n",
       " Param(parent='CrossValidatorModel_d01b3939eab6', name='evaluator', doc='evaluator used to select hyper-parameters that maximize the validator metric'),\n",
       " Param(parent='CrossValidatorModel_d01b3939eab6', name='seed', doc='random seed.')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvModelSVC.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste = cvModelSVC.bestModel.stages[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Param(parent='LinearSVC_ed658f57cfca', name='aggregationDepth', doc='suggested depth for treeAggregate (>= 2)'): 2,\n",
       " Param(parent='LinearSVC_ed658f57cfca', name='featuresCol', doc='features column name'): 'features',\n",
       " Param(parent='LinearSVC_ed658f57cfca', name='fitIntercept', doc='whether to fit an intercept term'): True,\n",
       " Param(parent='LinearSVC_ed658f57cfca', name='labelCol', doc='label column name'): 'label',\n",
       " Param(parent='LinearSVC_ed658f57cfca', name='maxIter', doc='maximum number of iterations (>= 0)'): 15,\n",
       " Param(parent='LinearSVC_ed658f57cfca', name='predictionCol', doc='prediction column name'): 'prediction',\n",
       " Param(parent='LinearSVC_ed658f57cfca', name='rawPredictionCol', doc='raw prediction (a.k.a. confidence) column name'): 'rawPrediction',\n",
       " Param(parent='LinearSVC_ed658f57cfca', name='regParam', doc='regularization parameter (>= 0)'): 0.1,\n",
       " Param(parent='LinearSVC_ed658f57cfca', name='standardization', doc='whether to standardize the training features before fitting the model'): True,\n",
       " Param(parent='LinearSVC_ed658f57cfca', name='threshold', doc='threshold in binary classification prediction applied to rawPrediction'): 0.0,\n",
       " Param(parent='LinearSVC_ed658f57cfca', name='tol', doc='the convergence tolerance for iterative algorithms (>= 0)'): 1e-06}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teste.extractParamMap()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The best model is LinearSVC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
